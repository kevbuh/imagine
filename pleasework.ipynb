{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Using cached diffusers-0.17.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp311-cp311-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors\n",
      "  Downloading safetensors-0.3.1-cp311-cp311-macosx_10_11_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow (from diffusers)\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting filelock (from diffusers)\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub>=0.13.2 (from diffusers)\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from diffusers) (6.7.0)\n",
      "Collecting numpy (from diffusers)\n",
      "  Downloading numpy-1.25.0-cp311-cp311-macosx_10_9_x86_64.whl (20.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from diffusers)\n",
      "  Downloading regex-2023.6.3-cp311-cp311-macosx_10_9_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.7/294.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests (from diffusers)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0-cp311-cp311-macosx_10_9_x86_64.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.6/188.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-macosx_10_11_universal2.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: psutil in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Collecting torch>=1.6.0 (from accelerate)\n",
      "  Downloading torch-2.0.1-cp311-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from huggingface-hub>=0.13.2->diffusers)\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.6.3)\n",
      "Collecting sympy (from torch>=1.6.0->accelerate)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.6.0->accelerate)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch>=1.6.0->accelerate)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.15.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->diffusers)\n",
      "  Downloading charset_normalizer-3.1.0-cp311-cp311-macosx_10_9_x86_64.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->diffusers)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->diffusers)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->diffusers)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.6.0->accelerate)\n",
      "  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->accelerate)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tokenizers, safetensors, mpmath, urllib3, tqdm, sympy, regex, pyyaml, Pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, scipy, requests, jinja2, torch, huggingface-hub, transformers, diffusers, accelerate\n",
      "Successfully installed MarkupSafe-2.1.3 Pillow-9.5.0 accelerate-0.20.3 certifi-2023.5.7 charset-normalizer-3.1.0 diffusers-0.17.1 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.15.1 idna-3.4 jinja2-3.1.2 mpmath-1.3.0 networkx-3.1 numpy-1.25.0 pyyaml-6.0 regex-2023.6.3 requests-2.31.0 safetensors-0.3.1 scipy-1.10.1 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 tqdm-4.65.0 transformers-4.30.2 urllib3-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers transformers accelerate scipy safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "import torch\n",
    "import time\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_5298.heic                   \u001b[1m\u001b[36mframes\u001b[m\u001b[m\n",
      "IMG_5298.jpg                    hugging.ipynb\n",
      "README.md                       hugging.py\n",
      "astronaut_rides_horse.png       pleasework.ipynb\n",
      "automatic.ipynb                 \u001b[1m\u001b[36mresearch\u001b[m\u001b[m\n",
      "bladerunner2049walking.mp4      todo.py\n",
      "bladerunner2049walkingshort.mp4 utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd ./research/ml-stable-diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACKNOWLEDGEMENTS\n",
      "CODE_OF_CONDUCT.md\n",
      "CONTRIBUTING.md\n",
      "LICENSE.md\n",
      "Package.swift\n",
      "README.md\n",
      "\u001b[1m\u001b[36massets\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mcoreml-stable-diffusion-2-base-palettized_original_compiled\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mnoodle\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36moutput_images\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mpython_coreml_stable_diffusion\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mpython_coreml_stable_diffusion.egg-info\u001b[m\u001b[m\n",
      "requirements.txt\n",
      "setup.py\n",
      "\u001b[1m\u001b[36mswift\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mtests\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools>=7.0b1 (from -r requirements.txt (line 1))\n",
      "  Downloading coremltools-7.0b1-cp311-none-macosx_10_15_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: diffusers[torch] in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
      "Requirement already satisfied: torch in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.0.1)\n",
      "Collecting transformers==4.29.2 (from -r requirements.txt (line 4))\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Requirement already satisfied: scipy in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.10.1)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 6))\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting pytest (from -r requirements.txt (line 7))\n",
      "  Using cached pytest-7.3.2-py3-none-any.whl (320 kB)\n",
      "Requirement already satisfied: filelock in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from transformers==4.29.2->-r requirements.txt (line 4)) (4.65.0)\n",
      "Collecting protobuf<=4.0.0,>=3.1.0 (from coremltools>=7.0b1->-r requirements.txt (line 1))\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from coremltools>=7.0b1->-r requirements.txt (line 1)) (1.12)\n",
      "Collecting attrs (from coremltools>=7.0b1->-r requirements.txt (line 1))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting cattrs (from coremltools>=7.0b1->-r requirements.txt (line 1))\n",
      "  Using cached cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
      "Collecting pyaml (from coremltools>=7.0b1->-r requirements.txt (line 1))\n",
      "  Using cached pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: Pillow in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from diffusers[torch]->-r requirements.txt (line 2)) (9.5.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from diffusers[torch]->-r requirements.txt (line 2)) (6.7.0)\n",
      "Requirement already satisfied: accelerate>=0.11.0 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from diffusers[torch]->-r requirements.txt (line 2)) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (4.6.3)\n",
      "Requirement already satisfied: networkx in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting iniconfig (from pytest->-r requirements.txt (line 7))\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest->-r requirements.txt (line 7))\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: psutil in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from accelerate>=0.11.0->diffusers[torch]->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: fsspec in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2->-r requirements.txt (line 4)) (2023.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from importlib-metadata->diffusers[torch]->-r requirements.txt (line 2)) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r requirements.txt (line 4)) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages (from sympy->coremltools>=7.0b1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Installing collected packages: threadpoolctl, pyaml, protobuf, pluggy, joblib, iniconfig, attrs, scikit-learn, pytest, cattrs, transformers, coremltools\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-coreml-stable-diffusion 1.0.0 requires numpy<1.24, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-23.1.0 cattrs-23.1.2 coremltools-7.0b1 iniconfig-2.0.0 joblib-1.2.0 pluggy-1.2.0 protobuf-3.20.3 pyaml-23.5.9 pytest-7.3.2 scikit-learn-1.2.2 threadpoolctl-3.1.0 transformers-4.29.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)ackage/Manifest.json: 100%|██████████| 617/617 [00:00<00:00, 2.46MB/s]\n",
      "Downloading (…)ackage/Manifest.json: 100%|██████████| 617/617 [00:00<00:00, 5.52MB/s]\n",
      "Downloading (…)ackage/Manifest.json: 100%|██████████| 617/617 [00:00<00:00, 765kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading model.mlmodel: 100%|██████████| 146k/146k [00:00<00:00, 847kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading model.mlmodel: 100%|██████████| 289k/289k [00:00<00:00, 1.25MB/s]\n",
      "Fetching 15 files:   7%|▋         | 1/15 [00:01<00:14,  1.05s/it]\n",
      "Downloading model.mlmodel: 100%|██████████| 723k/723k [00:00<00:00, 2.34MB/s]\n",
      "\n",
      "Downloading (…)ackage/Manifest.json: 100%|██████████| 617/617 [00:00<00:00, 3.56MB/s]\n",
      "\n",
      "Downloading (…)ackage/Manifest.json: 100%|██████████| 617/617 [00:00<00:00, 3.26MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading model.mlmodel: 100%|██████████| 147k/147k [00:00<00:00, 300kB/s]\n",
      "\n",
      "\n",
      "Downloading model.mlmodel: 100%|██████████| 115k/115k [00:00<00:00, 170kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading weight.bin: 100%|██████████| 68.4M/68.4M [03:05<00:00, 368kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading weight.bin: 100%|██████████| 99.0M/99.0M [04:08<00:00, 399kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading weight.bin: 100%|██████████| 246M/246M [08:00<00:00, 512kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading weight.bin: 100%|██████████| 608M/608M [14:43<00:00, 688kB/s]\n",
      "Downloading weight.bin: 100%|██████████| 1.72G/1.72G [24:44<00:00, 1.16MB/s]\n",
      "Fetching 15 files: 100%|██████████| 15/15 [24:45<00:00, 99.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded at models/coreml-stable-diffusion-v1-4_original_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"apple/coreml-stable-diffusion-v1-4\"\n",
    "variant = \"original/packages\"\n",
    "\n",
    "model_path = Path(\"./models\") / (repo_id.split(\"/\")[-1] + \"_\" + variant.replace(\"/\", \"_\"))\n",
    "snapshot_download(repo_id, allow_patterns=f\"{variant}/*\", local_dir=model_path, local_dir_use_symlinks=False)\n",
    "print(f\"Model downloaded at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Initializing StableDiffusionPipeline with CompVis/stable-diffusion-v1-4..\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Attention implementation in effect: AttentionImplementations.SPLIT_EINSUM\n",
      "INFO:__main__:Converting vae_decoder\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/diffusers/models/resnet.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/diffusers/models/resnet.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "INFO:__main__:Converting vae_decoder to CoreML..\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|▉| 368/369 [00:00<00:00, 3425.01 o\n",
      "Running MIL frontend_pytorch pipeline: 100%|█| 5/5 [00:00<00:00, 280.77 passes/s\n",
      "Running MIL default pipeline: 100%|████████| 64/64 [00:04<00:00, 13.73 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|█| 11/11 [00:00<00:00, 432.46 passe\n",
      "INFO:__main__:Saved vae_decoder model to models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n",
      "INFO:__main__:Saved vae_decoder into models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n",
      "INFO:__main__:Converted vae_decoder\n",
      "INFO:__main__:Converting unet\n",
      "INFO:__main__:Sample UNet inputs spec: {'sample': (torch.Size([2, 4, 64, 64]), torch.float32), 'timestep': (torch.Size([2]), torch.float32), 'encoder_hidden_states': (torch.Size([2, 768, 1, 77]), torch.float32)}\n",
      "INFO:__main__:JIT tracing..\n",
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/layer_norm.py:61: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert inputs.size(1) == self.num_channels\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Converting unet to CoreML..\n",
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:   0%|       | 0/7876 [00:00<?, ? ops/s]WARNING:coremltools:Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|▉| 7874/7876 [00:01<00:00, 5805.33\n",
      "Running MIL frontend_pytorch pipeline: 100%|█| 5/5 [00:00<00:00,  9.65 passes/s]\n",
      "Running MIL default pipeline: 100%|████████| 64/64 [03:27<00:00,  3.24s/ passes]\n",
      "Running MIL backend_mlprogram pipeline: 100%|█| 11/11 [00:00<00:00, 39.58 passes\n",
      "INFO:__main__:Saved unet model to models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage\n",
      "INFO:__main__:Saved unet into models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage\n",
      "INFO:__main__:Converted unet\n",
      "INFO:__main__:Converting text_encoder\n",
      "INFO:__main__:Sample inputs spec: {'input_ids': (torch.Size([1, 77]), torch.float32)}\n",
      "INFO:__main__:JIT tracing text_encoder..\n",
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/Users/kevinbuhler/opt/anaconda3/envs/please_work/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:324: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Converting text_encoder to CoreML..\n",
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:   0%|        | 0/813 [00:00<?, ? ops/s]WARNING:coremltools:Saving value type of float64 into a builtin type of fp32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  76%|▊| 614/813 [00:00<00:00, 6139.13 oWARNING:coremltools:Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|▉| 811/813 [00:00<00:00, 6252.46 o\n",
      "Running MIL frontend_pytorch pipeline: 100%|█| 5/5 [00:00<00:00, 212.73 passes/s\n",
      "Running MIL default pipeline: 100%|████████| 64/64 [00:06<00:00,  9.83 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|█| 11/11 [00:00<00:00, 424.71 passe\n",
      "INFO:__main__:Saved text_encoder model to models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage\n",
      "INFO:__main__:Saved text_encoder into models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage\n",
      "INFO:__main__:Converted text_encoder\n",
      "INFO:__main__:Converting safety_checker\n",
      "INFO:__main__:Sample inputs spec: {'clip_input': (torch.Size([1, 3, 224, 224]), torch.float32), 'images': (torch.Size([1, 512, 512, 3]), torch.float32), 'adjustment': (torch.Size([1]), torch.float32)}\n",
      "INFO:__main__:JIT tracing..\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Converting safety_checker to CoreML..\n",
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|▉| 1480/1482 [00:00<00:00, 6939.79\n",
      "Running MIL frontend_pytorch pipeline: 100%|█| 5/5 [00:00<00:00, 77.96 passes/s]\n",
      "Running MIL default pipeline: 100%|████████| 64/64 [00:15<00:00,  4.00 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|█| 11/11 [00:00<00:00, 230.91 passe\n",
      "INFO:__main__:Saved safety_checker model to models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage\n",
      "INFO:__main__:Converted safety_checker\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.torch2coreml --convert-unet --convert-text-encoder --convert-vae-decoder --convert-safety-checker -o models/coreml-stable-diffusion-v1-4_original_packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACKNOWLEDGEMENTS\n",
      "CODE_OF_CONDUCT.md\n",
      "CONTRIBUTING.md\n",
      "LICENSE.md\n",
      "Package.swift\n",
      "README.md\n",
      "\u001b[1m\u001b[36massets\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mcoreml-stable-diffusion-2-base-palettized_original_compiled\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mmodels\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mnoodle\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36moutput_images\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mpython_coreml_stable_diffusion\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mpython_coreml_stable_diffusion.egg-info\u001b[m\u001b[m\n",
      "requirements.txt\n",
      "setup.py\n",
      "\u001b[1m\u001b[36mswift\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mtests\u001b[m\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Setting random seed to 93\n",
      "INFO:__main__:Initializing PyTorch pipe for reference configuration\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:__main__:Loading Core ML models in memory from models/coreml-stable-diffusion-v1-4_original_packages\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.5 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 92.1 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 5.3 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 2.3 seconds.\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Initializing Core ML pipe for image generation\n",
      "INFO:__main__:Stable Diffusion configured to generate 512x512 images\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Beginning image generation.\n",
      "100%|███████████████████████████████████████████| 51/51 [00:22<00:00,  2.32it/s]\n",
      "INFO:__main__:Generated image has nsfw concept=False\n",
      "INFO:__main__:Saving generated image to output_images/a_photo_of_an_frog_riding_a_horse_on_mars_with_water/randomSeed_93_computeUnit_ALL_modelVersion_CompVis_stable-diffusion-v1-4.png\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!python -m python_coreml_stable_diffusion.pipeline --prompt \"a photo of an frog riding a horse on mars with water\" -i models/coreml-stable-diffusion-v1-4_original_packages -o output_images/ --compute-unit ALL --seed 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Setting random seed to 93\n",
      "INFO:__main__:Initializing PyTorch pipe for reference configuration\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:__main__:Loading Core ML models in memory from models/coreml-stable-diffusion-v1-4_original_packages\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.7 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 95.8 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 5.6 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 2.6 seconds.\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Initializing Core ML pipe for image generation\n",
      "INFO:__main__:Stable Diffusion configured to generate 512x512 images\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Beginning image generation.\n",
      "100%|███████████████████████████████████████████| 51/51 [00:22<00:00,  2.28it/s]\n",
      "INFO:__main__:Generated image has nsfw concept=False\n",
      "INFO:__main__:Saving generated image to output_images/a_photo_of_an_frog_with_naruto/randomSeed_93_computeUnit_ALL_modelVersion_CompVis_stable-diffusion-v1-4.png\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.pipeline --prompt \"a photo of an frog with naruto\" -i models/coreml-stable-diffusion-v1-4_original_packages -o output_images/ --compute-unit ALL --seed 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "usage: pipeline.py [-h] --prompt PROMPT -i I -o O [--seed SEED]\n",
      "                   [--model-version MODEL_VERSION]\n",
      "                   [--compute-unit {ALL,CPU_AND_GPU,CPU_ONLY,CPU_AND_NE}]\n",
      "                   [--scheduler {DDIM,DPMSolverMultistep,EulerAncestralDiscrete,EulerDiscrete,LMSDiscrete,PNDM}]\n",
      "                   [--num-inference-steps NUM_INFERENCE_STEPS]\n",
      "                   [--guidance-scale GUIDANCE_SCALE]\n",
      "                   [--controlnet [CONTROLNET ...]]\n",
      "                   [--controlnet-inputs [CONTROLNET_INPUTS ...]]\n",
      "                   [--negative-prompt NEGATIVE_PROMPT]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --prompt PROMPT       The text prompt to be used for text-to-image\n",
      "                        generation.\n",
      "  -i I                  Path to input directory with the .mlpackage files\n",
      "                        generated by\n",
      "                        python_coreml_stable_diffusion.torch2coreml\n",
      "  -o O\n",
      "  --seed SEED, -s SEED  Random seed to be able to reproduce results\n",
      "  --model-version MODEL_VERSION\n",
      "                        The pre-trained model checkpoint and configuration to\n",
      "                        restore. For available versions:\n",
      "                        https://huggingface.co/models?search=stable-diffusion\n",
      "  --compute-unit {ALL,CPU_AND_GPU,CPU_ONLY,CPU_AND_NE}\n",
      "                        The compute units to be used when executing Core ML\n",
      "                        models. Options: ('ALL', 'CPU_AND_GPU', 'CPU_ONLY',\n",
      "                        'CPU_AND_NE')\n",
      "  --scheduler {DDIM,DPMSolverMultistep,EulerAncestralDiscrete,EulerDiscrete,LMSDiscrete,PNDM}\n",
      "                        The scheduler to use for running the reverse diffusion\n",
      "                        process. If not specified, the default scheduler from\n",
      "                        the diffusers pipeline is utilized\n",
      "  --num-inference-steps NUM_INFERENCE_STEPS\n",
      "                        The number of iterations the unet model will be\n",
      "                        executed throughout the reverse diffusion process\n",
      "  --guidance-scale GUIDANCE_SCALE\n",
      "                        Controls the influence of the text prompt on sampling\n",
      "                        process (0=random images)\n",
      "  --controlnet [CONTROLNET ...]\n",
      "                        Enables ControlNet and use control-unet instead of\n",
      "                        unet for additional inputs. For Multi-Controlnet,\n",
      "                        provide the model names separated by spaces.\n",
      "  --controlnet-inputs [CONTROLNET_INPUTS ...]\n",
      "                        Image paths for ControlNet inputs. Please enter images\n",
      "                        corresponding to each controlnet provided at\n",
      "                        --controlnet option in same order.\n",
      "  --negative-prompt NEGATIVE_PROMPT\n",
      "                        The negative text prompt to be used for text-to-image\n",
      "                        generation.\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.pipeline -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "usage: pipeline.py [-h] --prompt PROMPT -i I -o O [--seed SEED]\n",
      "                   [--model-version MODEL_VERSION]\n",
      "                   [--compute-unit {ALL,CPU_AND_GPU,CPU_ONLY,CPU_AND_NE}]\n",
      "                   [--scheduler {DDIM,DPMSolverMultistep,EulerAncestralDiscrete,EulerDiscrete,LMSDiscrete,PNDM}]\n",
      "                   [--num-inference-steps NUM_INFERENCE_STEPS]\n",
      "                   [--guidance-scale GUIDANCE_SCALE]\n",
      "                   [--controlnet [CONTROLNET ...]]\n",
      "                   [--controlnet-inputs [CONTROLNET_INPUTS ...]]\n",
      "                   [--negative-prompt NEGATIVE_PROMPT]\n",
      "pipeline.py: error: the following arguments are required: --prompt, -i, -o\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.pipeline --controlnet lllyasviel/sd-controlnet-mlsd lllyasviel/sd-controlnet-depth --prompt \"an awe inspiring water fall\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Initializing StableDiffusionPipeline with runwayml/stable-diffusion-v1-5..\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Attention implementation in effect: AttentionImplementations.SPLIT_EINSUM\n",
      "INFO:__main__:Converting controlnet\n",
      "INFO:__main__:Sample ControlNet inputs spec: {'sample': (torch.Size([2, 4, 64, 64]), torch.float32), 'timestep': (torch.Size([2]), torch.float32), 'encoder_hidden_states': (torch.Size([2, 768, 1, 77]), torch.float32), 'controlnet_cond': (torch.Size([2, 3, 512, 512]), torch.float32)}\n",
      "Downloading (…)ch_model.safetensors: 100%|█| 1.45G/1.45G [14:32<00:00, 1.66MB/s]\n",
      "INFO:__main__:JIT tracing..\n",
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/layer_norm.py:61: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert inputs.size(1) == self.num_channels\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Converting controlnet_lllyasviel_sd-controlnet-seg to CoreML..\n",
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:   0%|       | 0/3647 [00:00<?, ? ops/s]WARNING:coremltools:Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|▉| 3644/3647 [00:00<00:00, 7507.46\n",
      "Running MIL frontend_pytorch pipeline: 100%|█| 5/5 [00:00<00:00, 33.31 passes/s]\n",
      "Running MIL default pipeline: 100%|████████| 64/64 [00:51<00:00,  1.24 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|█| 11/11 [00:00<00:00, 89.01 passes\n",
      "INFO:__main__:Saved controlnet_lllyasviel_sd-controlnet-seg model to models/ControlNet_lllyasviel_sd-controlnet-seg.mlpackage\n",
      "INFO:__main__:Saved controlnet into models/ControlNet_lllyasviel_sd-controlnet-seg.mlpackage\n",
      "INFO:__main__:Converted controlnet\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.torch2coreml --convert-controlnet lllyasviel/sd-controlnet-seg -o models/  --model-version runwayml/stable-diffusion-v1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Setting random seed to 93\n",
      "INFO:__main__:Initializing PyTorch pipe for reference configuration\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:__main__:Loading Core ML models in memory from models/coreml-stable-diffusion-v1-4_original_packages\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.6 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 88.8 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 5.4 seconds.\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 2.4 seconds.\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Initializing Core ML pipe for image generation\n",
      "INFO:__main__:Stable Diffusion configured to generate 512x512 images\n",
      "INFO:__main__:Done.\n",
      "INFO:__main__:Beginning image generation.\n",
      "100%|███████████████████████████████████████████| 51/51 [00:23<00:00,  2.21it/s]\n",
      "INFO:__main__:Generated image has nsfw concept=False\n",
      "INFO:__main__:Saving generated image to output_images/an_awe_inspiring_water_fall/randomSeed_93_computeUnit_CPU_AND_NE_modelVersion_CompVis_stable-diffusion-v1-4.png\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.pipeline --prompt \"an awe inspiring water fall\" -i models/coreml-stable-diffusion-v1-4_original_packages -o output_images/ --compute-unit CPU_AND_NE --negative-prompt \"ugly, boring, monochromatic\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py:8: FutureWarning: Importing `DiffusionPipeline` or `ImagePipelineOutput` from diffusers.pipeline_utils is deprecated. Please import from diffusers.pipelines.pipeline_utils instead.\n",
      "  from diffusers.pipeline_utils import DiffusionPipeline\n",
      "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:Torch version 2.0.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.0.0 is the most recent version that has been tested.\n",
      "INFO:__main__:Setting random seed to 93\n",
      "INFO:__main__:Initializing PyTorch pipe for reference configuration\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "INFO:__main__:Removed PyTorch pipe to reduce peak memory consumption\n",
      "INFO:python_coreml_stable_diffusion.coreml_model:Loading control-unet mlpackage\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py\", line 656, in <module>\n",
      "    main(args)\n",
      "  File \"/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py\", line 559, in main\n",
      "    coreml_pipe = get_coreml_pipe(pytorch_pipe=pytorch_pipe,\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py\", line 489, in get_coreml_pipe\n",
      "    coreml_pipe_kwargs[\"unet\"] = _load_mlpackage(\n",
      "                                 ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kevinbuhler/Code/imagine/research/ml-stable-diffusion/python_coreml_stable_diffusion/coreml_model.py\", line 96, in _load_mlpackage\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: control-unet CoreML model doesn't exist at models/coreml-stable-diffusion-v1-4_original_packages/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_control-unet.mlpackage\n"
     ]
    }
   ],
   "source": [
    "!python -m python_coreml_stable_diffusion.pipeline --prompt \"an awe inspiring water fall\" -i models/coreml-stable-diffusion-v1-4_original_packages -o output_images/ --compute-unit CPU_AND_NE --negative-prompt \"ugly, boring, monochromatic\" --controlnet ControlNet_lllyasviel_sd-controlnet-seg.mlpackage --controlnet-inputs output_images/masked_kevin_seg.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "please_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
